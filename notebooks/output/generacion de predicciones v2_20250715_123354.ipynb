{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c8c1612",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [1]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d780c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed16b364-08fe-467b-8854-178beb28c6c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T16:33:56.239859Z",
     "iopub.status.busy": "2025-07-15T16:33:56.239462Z",
     "iopub.status.idle": "2025-07-15T16:33:58.024816Z",
     "shell.execute_reply": "2025-07-15T16:33:58.023803Z"
    },
    "papermill": {
     "duration": 1.792528,
     "end_time": "2025-07-15T16:33:58.025887",
     "exception": true,
     "start_time": "2025-07-15T16:33:56.233359",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mticker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mticker\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmdates\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, OneHotEncoder\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# generación de predicción por tipo de vehículo y tipo de mantenimiento\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas.tseries.offsets as offsets\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# 🔧 Configuración de conexión a MySQL\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"roundhouse.proxy.rlwy.net\",\n",
    "    \"port\": 38517,\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"wZGotyxIDqpAtQjPxNuxxezSbbroztiw\",\n",
    "    \"database\": \"railway\"\n",
    "}\n",
    "\n",
    "# 📥 Consulta SQL\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    FechaElaboracion,\n",
    "    Debito,\n",
    "    TipoMantenimiento,\n",
    "    Categoria,\n",
    "    TipoMatricula,\n",
    "    NombreVehiculo,\n",
    "    IdentificacionTercero\n",
    "FROM Hechos_Mantenimiento\n",
    "WHERE Debito IS NOT NULL \n",
    "  AND FechaElaboracion IS NOT NULL\n",
    "  AND TipoMantenimiento IS NOT NULL\n",
    "  AND Categoria IS NOT NULL\n",
    "  AND TipoMatricula IS NOT NULL\n",
    "  AND NombreVehiculo IS NOT NULL\n",
    "  AND IdentificacionTercero IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# 📊 Cargar datos\n",
    "conn = mysql.connector.connect(**DB_CONFIG)\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "df['FechaElaboracion'] = pd.to_datetime(df['FechaElaboracion'])\n",
    "\n",
    "# 📂 Crear carpeta de salida\n",
    "os.makedirs(\"graficas_rf_vehiculo\", exist_ok=True)\n",
    "resultados = []\n",
    "\n",
    "# 🔁 Por cada vehículo y tipo de mantenimiento\n",
    "for vehiculo in df['NombreVehiculo'].unique():\n",
    "    df_vehiculo = df[df['NombreVehiculo'] == vehiculo]\n",
    "    for tipo in df_vehiculo['TipoMantenimiento'].unique():\n",
    "        df_tipo = df_vehiculo[df_vehiculo['TipoMantenimiento'] == tipo].copy()\n",
    "        if df_tipo.empty:\n",
    "            continue\n",
    "\n",
    "        # Agrupar por mes\n",
    "        df_tipo['AñoMes'] = df_tipo['FechaElaboracion'].dt.to_period('M')\n",
    "        df_hist_grouped = df_tipo.groupby('AñoMes').agg({\n",
    "            'Debito': 'sum',\n",
    "            'Categoria': lambda x: x.mode()[0],\n",
    "            'TipoMatricula': lambda x: x.mode()[0],\n",
    "            'IdentificacionTercero': lambda x: x.mode()[0]\n",
    "        }).reset_index()\n",
    "\n",
    "        df_hist_grouped['FechaElaboracion'] = df_hist_grouped['AñoMes'].dt.to_timestamp()\n",
    "        df_hist_grouped['Año'] = df_hist_grouped['FechaElaboracion'].dt.year\n",
    "        df_hist_grouped['Mes'] = df_hist_grouped['FechaElaboracion'].dt.month\n",
    "        df_hist_grouped['TipoMantenimiento'] = tipo\n",
    "        df_hist_grouped['NombreVehiculo'] = vehiculo\n",
    "\n",
    "        # Entrenamiento del modelo\n",
    "        X = df_hist_grouped[['Año', 'Mes', 'TipoMantenimiento', 'Categoria', 'TipoMatricula', 'NombreVehiculo', 'IdentificacionTercero']]\n",
    "        y = df_hist_grouped['Debito']\n",
    "\n",
    "        preprocessor = ColumnTransformer([\n",
    "            ('num', StandardScaler(), ['Año', 'Mes']),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), ['TipoMantenimiento', 'Categoria', 'TipoMatricula', 'NombreVehiculo', 'IdentificacionTercero'])\n",
    "        ])\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('regresion', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "        ])\n",
    "\n",
    "        pipeline.fit(X, y)\n",
    "        y_pred = pipeline.predict(X)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "\n",
    "        # Generar 12 meses futuros\n",
    "        ultima_fecha = df_hist_grouped['FechaElaboracion'].max()\n",
    "        fechas_futuras = pd.date_range(start=ultima_fecha + offsets.MonthBegin(1), periods=12, freq='MS')\n",
    "\n",
    "        categoria = df_hist_grouped['Categoria'].mode()[0]\n",
    "        tipomatricula = df_hist_grouped['TipoMatricula'].mode()[0]\n",
    "        tercero = df_hist_grouped['IdentificacionTercero'].mode()[0]\n",
    "\n",
    "        df_futuro = pd.DataFrame({\n",
    "            'Año': fechas_futuras.year,\n",
    "            'Mes': fechas_futuras.month,\n",
    "            'TipoMantenimiento': tipo,\n",
    "            'Categoria': categoria,\n",
    "            'TipoMatricula': tipomatricula,\n",
    "            'NombreVehiculo': vehiculo,\n",
    "            'IdentificacionTercero': tercero,\n",
    "            'FechaElaboracion': fechas_futuras\n",
    "        })\n",
    "\n",
    "        y_futuro = pipeline.predict(df_futuro.drop(columns='FechaElaboracion'))\n",
    "        df_futuro['Debito'] = y_futuro\n",
    "        df_futuro['Prediccion'] = y_futuro\n",
    "        df_futuro['R2'] = r2\n",
    "        df_futuro['Origen'] = 'Predicción'\n",
    "\n",
    "        df_hist_grouped['Prediccion'] = y_pred\n",
    "        df_hist_grouped['R2'] = r2\n",
    "        df_hist_grouped['Origen'] = 'Histórico'\n",
    "\n",
    "        df_resultado = pd.concat([\n",
    "            df_hist_grouped[['FechaElaboracion', 'Debito', 'Prediccion', 'R2', 'Origen', 'NombreVehiculo', 'TipoMantenimiento']],\n",
    "            df_futuro[['FechaElaboracion', 'Debito', 'Prediccion', 'R2', 'Origen', 'NombreVehiculo', 'TipoMantenimiento']]\n",
    "        ]).sort_values(by='FechaElaboracion')\n",
    "\n",
    "        resultados.append(df_resultado)\n",
    "\n",
    "        # 📈 Generar gráfico\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        df_h = df_resultado[df_resultado['Origen'] == 'Histórico']\n",
    "        df_p = df_resultado[df_resultado['Origen'] == 'Predicción']\n",
    "\n",
    "        plt.plot(df_h['FechaElaboracion'], df_h['Debito'], marker='o', linestyle='-', label='Histórico')\n",
    "        plt.plot(df_p['FechaElaboracion'], df_p['Prediccion'], marker='x', linestyle='--', color='orange', label='Predicción')\n",
    "\n",
    "        plt.title(f\"{vehiculo} - Tipo: {tipo}\")\n",
    "        plt.xlabel(\"Fecha\")\n",
    "        plt.ylabel(\"Costo (Débito)\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "        plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "        plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.text(0.98, 0.02, f\"R² = {r2:.4f}\", transform=plt.gca().transAxes,\n",
    "                 fontsize=10, ha='right', va='bottom',\n",
    "                 bbox=dict(facecolor='white', alpha=0.6, edgecolor='gray'))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        file_name = f\"graficas_rf_vehiculo/{vehiculo.replace(' ', '_')}_{tipo.replace(' ', '_')}.png\"\n",
    "        plt.savefig(file_name)\n",
    "        plt.close()\n",
    "\n",
    "# 📤 Exportar Excel\n",
    "df_final = pd.concat(resultados, ignore_index=True)\n",
    "df_final.to_excel(\"Prediccion_Costos_RF_Por_Vehiculo_Tipo.xlsx\", index=False)\n",
    "\n",
    "# 📥 Insertar en la tabla MySQL: Predicciones_Vehiculo_Tipo\n",
    "df_insert = df_final[['NombreVehiculo', 'TipoMantenimiento', 'FechaElaboracion', 'Debito', 'Origen']].copy()\n",
    "df_insert.columns = ['NombreVehiculo', 'TipoMantenimiento', 'Fecha', 'Costo', 'Origen']\n",
    "df_insert = df_insert.dropna(subset=['Costo'])\n",
    "df_insert['Costo'] = df_insert['Costo'].round(2)\n",
    "\n",
    "# Conexión SQLAlchemy\n",
    "DB_URL = f\"mysql+mysqlconnector://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for _, row in df_insert.iterrows():\n",
    "        query_insert = text(\"\"\"\n",
    "            INSERT INTO Predicciones_Vehiculo_Tipo (NombreVehiculo, TipoMantenimiento, Fecha, Costo, Origen)\n",
    "            VALUES (:NombreVehiculo, :TipoMantenimiento, :Fecha, :Costo, :Origen)\n",
    "            ON DUPLICATE KEY UPDATE Costo = VALUES(Costo)\n",
    "        \"\"\")\n",
    "        conn.execute(query_insert, {\n",
    "            \"NombreVehiculo\": row['NombreVehiculo'],\n",
    "            \"TipoMantenimiento\": row['TipoMantenimiento'],\n",
    "            \"Fecha\": row['Fecha'],\n",
    "            \"Costo\": row['Costo'],\n",
    "            \"Origen\": row['Origen']\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702a072-cd2f-4fcc-9f58-84d0de4d9000",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generación de predicción general por tipo de mantenimiento\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime\n",
    "import pandas.tseries.offsets as offsets\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# 🔧 CONEXIÓN A LA BASE DE DATOS\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"roundhouse.proxy.rlwy.net\",\n",
    "    \"port\": 38517,\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"wZGotyxIDqpAtQjPxNuxxezSbbroztiw\",\n",
    "    \"database\": \"railway\"\n",
    "}\n",
    "\n",
    "# 📥 CONSULTA\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    FechaElaboracion,\n",
    "    Debito,\n",
    "    TipoMantenimiento,\n",
    "    Categoria,\n",
    "    TipoMatricula,\n",
    "    NombreVehiculo,\n",
    "    IdentificacionTercero\n",
    "FROM Hechos_Mantenimiento\n",
    "WHERE Debito IS NOT NULL \n",
    "  AND FechaElaboracion IS NOT NULL\n",
    "  AND TipoMantenimiento IS NOT NULL\n",
    "  AND Categoria IS NOT NULL\n",
    "  AND TipoMatricula IS NOT NULL\n",
    "  AND NombreVehiculo IS NOT NULL\n",
    "  AND IdentificacionTercero IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# 📊 CARGAR DATOS\n",
    "conn = mysql.connector.connect(**DB_CONFIG)\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "df['FechaElaboracion'] = pd.to_datetime(df['FechaElaboracion'])\n",
    "\n",
    "# 📂 CARPETA PARA GRÁFICAS\n",
    "os.makedirs(\"graficas_rf_agrupado\", exist_ok=True)\n",
    "resultados = []\n",
    "\n",
    "# 🔁 POR CADA TIPO DE MANTENIMIENTO\n",
    "for tipo in df['TipoMantenimiento'].unique():\n",
    "    df_tipo = df[df['TipoMantenimiento'] == tipo].copy()\n",
    "\n",
    "    # 📆 AGRUPAR POR MES\n",
    "    df_tipo['AñoMes'] = df_tipo['FechaElaboracion'].dt.to_period('M')\n",
    "    df_hist_grouped = df_tipo.groupby('AñoMes').agg({\n",
    "        'Debito': 'sum',\n",
    "        'Categoria': lambda x: x.mode()[0],\n",
    "        'TipoMatricula': lambda x: x.mode()[0],\n",
    "        'NombreVehiculo': lambda x: x.mode()[0],\n",
    "        'IdentificacionTercero': lambda x: x.mode()[0]\n",
    "    }).reset_index()\n",
    "\n",
    "    df_hist_grouped['FechaElaboracion'] = df_hist_grouped['AñoMes'].dt.to_timestamp()\n",
    "    df_hist_grouped['Año'] = df_hist_grouped['FechaElaboracion'].dt.year\n",
    "    df_hist_grouped['Mes'] = df_hist_grouped['FechaElaboracion'].dt.month\n",
    "    df_hist_grouped['TipoMantenimiento'] = tipo\n",
    "\n",
    "    # 🎓 ENTRENAR MODELO\n",
    "    X = df_hist_grouped[['Año', 'Mes', 'TipoMantenimiento', 'Categoria', 'TipoMatricula', 'NombreVehiculo', 'IdentificacionTercero']]\n",
    "    y = df_hist_grouped['Debito']\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), ['Año', 'Mes']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['TipoMantenimiento', 'Categoria', 'TipoMatricula', 'NombreVehiculo', 'IdentificacionTercero'])\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('regresion', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X, y)\n",
    "    y_pred = pipeline.predict(X)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "\n",
    "    # 📅 GENERAR 12 MESES FUTUROS\n",
    "    ultima_fecha = df_hist_grouped['FechaElaboracion'].max()\n",
    "    fechas_futuras = pd.date_range(start=ultima_fecha + offsets.MonthBegin(1), periods=12, freq='MS')\n",
    "\n",
    "    categoria = df_hist_grouped['Categoria'].mode()[0]\n",
    "    tipomatricula = df_hist_grouped['TipoMatricula'].mode()[0]\n",
    "    vehiculo = df_hist_grouped['NombreVehiculo'].mode()[0]\n",
    "    tercero = df_hist_grouped['IdentificacionTercero'].mode()[0]\n",
    "\n",
    "    df_futuro = pd.DataFrame({\n",
    "        'Año': fechas_futuras.year,\n",
    "        'Mes': fechas_futuras.month,\n",
    "        'TipoMantenimiento': tipo,\n",
    "        'Categoria': categoria,\n",
    "        'TipoMatricula': tipomatricula,\n",
    "        'NombreVehiculo': vehiculo,\n",
    "        'IdentificacionTercero': tercero,\n",
    "        'FechaElaboracion': fechas_futuras\n",
    "    })\n",
    "\n",
    "    y_futuro = pipeline.predict(df_futuro.drop(columns='FechaElaboracion'))\n",
    "    df_futuro['Debito'] = y_futuro\n",
    "    df_futuro['Prediccion'] = y_futuro\n",
    "    df_futuro['R2'] = r2\n",
    "    df_futuro['Origen'] = 'Predicción'\n",
    "\n",
    "    df_hist_grouped['Prediccion'] = y_pred\n",
    "    df_hist_grouped['R2'] = r2\n",
    "    df_hist_grouped['Origen'] = 'Histórico'\n",
    "\n",
    "    df_resultado = pd.concat([\n",
    "        df_hist_grouped[['FechaElaboracion', 'Debito', 'Prediccion', 'R2', 'Origen', 'TipoMantenimiento']],\n",
    "        df_futuro[['FechaElaboracion', 'Debito', 'Prediccion', 'R2', 'Origen', 'TipoMantenimiento']]\n",
    "    ]).sort_values(by='FechaElaboracion')\n",
    "\n",
    "    resultados.append(df_resultado)\n",
    "\n",
    "    # 📈 GRAFICAR\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    df_h = df_resultado[df_resultado['Origen'] == 'Histórico']\n",
    "    df_p = df_resultado[df_resultado['Origen'] == 'Predicción']\n",
    "\n",
    "    plt.plot(df_h['FechaElaboracion'], df_h['Debito'], marker='o', linestyle='-', label='Histórico')\n",
    "    plt.plot(df_p['FechaElaboracion'], df_p['Prediccion'], marker='x', linestyle='--', color='orange', label='Predicción')\n",
    "\n",
    "    plt.title(f\"Costo Mantenimiento - Tipo: {tipo}\")\n",
    "    plt.xlabel(\"Fecha\")\n",
    "    plt.ylabel(\"Costo (Débito)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.text(\n",
    "        0.98, 0.02, f\"R² = {r2:.4f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=10, ha='right', va='bottom',\n",
    "        bbox=dict(facecolor='white', alpha=0.6, edgecolor='gray')\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    archivo = f\"graficas_rf_agrupado/Modelo_RF_{tipo.replace(' ', '_')}.png\"\n",
    "    plt.savefig(archivo)\n",
    "    plt.close()\n",
    "\n",
    "# 💾 EXPORTAR A EXCEL\n",
    "df_final = pd.concat(resultados, ignore_index=True)\n",
    "df_final.to_excel(\"Prediccion_Costos_RF_Mensual_Agrupado.xlsx\", index=False)\n",
    "\n",
    "# 📥 INSERTAR EN MYSQL: Predicciones_Tipo_Mantenimiento\n",
    "df_insert = df_final[['TipoMantenimiento', 'FechaElaboracion', 'Debito', 'Origen']].copy()\n",
    "df_insert.columns = ['TipoMantenimiento', 'Fecha', 'Costo', 'Origen']\n",
    "df_insert = df_insert.dropna(subset=['Costo'])\n",
    "df_insert['Costo'] = df_insert['Costo'].round(2)\n",
    "\n",
    "# 🔌 Conexión con SQLAlchemy\n",
    "DB_URL = f\"mysql+mysqlconnector://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for _, row in df_insert.iterrows():\n",
    "        query_insert = text(\"\"\"\n",
    "            INSERT INTO Predicciones_Tipo_Mantenimiento (TipoMantenimiento, Fecha, Costo, Origen)\n",
    "            VALUES (:TipoMantenimiento, :Fecha, :Costo, :Origen)\n",
    "            ON DUPLICATE KEY UPDATE Costo = VALUES(Costo)\n",
    "        \"\"\")\n",
    "        conn.execute(query_insert, {\n",
    "            \"TipoMantenimiento\": row['TipoMantenimiento'],\n",
    "            \"Fecha\": row['Fecha'],\n",
    "            \"Costo\": row['Costo'],\n",
    "            \"Origen\": row['Origen']\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881635b5-2dc2-495f-a901-211be5330f10",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.048082,
   "end_time": "2025-07-15T16:33:58.474642",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/generacion de predicciones v2.ipynb",
   "output_path": "notebooks/output/generacion de predicciones v2_20250715_123354.ipynb",
   "parameters": {},
   "start_time": "2025-07-15T16:33:54.426560",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}