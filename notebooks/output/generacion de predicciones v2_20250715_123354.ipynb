{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c8c1612",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [1]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d780c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed16b364-08fe-467b-8854-178beb28c6c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T16:33:56.239859Z",
     "iopub.status.busy": "2025-07-15T16:33:56.239462Z",
     "iopub.status.idle": "2025-07-15T16:33:58.024816Z",
     "shell.execute_reply": "2025-07-15T16:33:58.023803Z"
    },
    "papermill": {
     "duration": 1.792528,
     "end_time": "2025-07-15T16:33:58.025887",
     "exception": true,
     "start_time": "2025-07-15T16:33:56.233359",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mticker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mticker\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmdates\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, OneHotEncoder\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# generaci贸n de predicci贸n por tipo de veh铆culo y tipo de mantenimiento\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas.tseries.offsets as offsets\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "#  Configuraci贸n de conexi贸n a MySQL\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"roundhouse.proxy.rlwy.net\",\n",
    "    \"port\": 38517,\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"wZGotyxIDqpAtQjPxNuxxezSbbroztiw\",\n",
    "    \"database\": \"railway\"\n",
    "}\n",
    "\n",
    "#  Consulta SQL\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    FechaElaboracion,\n",
    "    Debito,\n",
    "    TipoMantenimiento,\n",
    "    Categoria,\n",
    "    TipoMatricula,\n",
    "    NombreVehiculo,\n",
    "    IdentificacionTercero\n",
    "FROM Hechos_Mantenimiento\n",
    "WHERE Debito IS NOT NULL \n",
    "  AND FechaElaboracion IS NOT NULL\n",
    "  AND TipoMantenimiento IS NOT NULL\n",
    "  AND Categoria IS NOT NULL\n",
    "  AND TipoMatricula IS NOT NULL\n",
    "  AND NombreVehiculo IS NOT NULL\n",
    "  AND IdentificacionTercero IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "#  Cargar datos\n",
    "conn = mysql.connector.connect(**DB_CONFIG)\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "df['FechaElaboracion'] = pd.to_datetime(df['FechaElaboracion'])\n",
    "\n",
    "#  Crear carpeta de salida\n",
    "os.makedirs(\"graficas_rf_vehiculo\", exist_ok=True)\n",
    "resultados = []\n",
    "\n",
    "#  Por cada veh铆culo y tipo de mantenimiento\n",
    "for vehiculo in df['NombreVehiculo'].unique():\n",
    "    df_vehiculo = df[df['NombreVehiculo'] == vehiculo]\n",
    "    for tipo in df_vehiculo['TipoMantenimiento'].unique():\n",
    "        df_tipo = df_vehiculo[df_vehiculo['TipoMantenimiento'] == tipo].copy()\n",
    "        if df_tipo.empty:\n",
    "            continue\n",
    "\n",
    "        # Agrupar por mes\n",
    "        df_tipo['A帽oMes'] = df_tipo['FechaElaboracion'].dt.to_period('M')\n",
    "        df_hist_grouped = df_tipo.groupby('A帽oMes').agg({\n",
    "            'Debito': 'sum',\n",
    "            'Categoria': lambda x: x.mode()[0],\n",
    "            'TipoMatricula': lambda x: x.mode()[0],\n",
    "            'IdentificacionTercero': lambda x: x.mode()[0]\n",
    "        }).reset_index()\n",
    "\n",
    "        df_hist_grouped['FechaElaboracion'] = df_hist_grouped['A帽oMes'].dt.to_timestamp()\n",
    "        df_hist_grouped['A帽o'] = df_hist_grouped['FechaElaboracion'].dt.year\n",
    "        df_hist_grouped['Mes'] = df_hist_grouped['FechaElaboracion'].dt.month\n",
    "        df_hist_grouped['TipoMantenimiento'] = tipo\n",
    "        df_hist_grouped['NombreVehiculo'] = vehiculo\n",
    "\n",
    "        # Entrenamiento del modelo\n",
    "        X = df_hist_grouped[['A帽o', 'Mes', 'TipoMantenimiento', 'Categoria', 'TipoMatricula', 'NombreVehiculo', 'IdentificacionTercero']]\n",
    "        y = df_hist_grouped['Debito']\n",
    "\n",
    "        preprocessor = ColumnTransformer([\n",
    "            ('num', StandardScaler(), ['A帽o', 'Mes']),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), ['TipoMantenimiento', 'Categoria', 'TipoMatricula', 'NombreVehiculo', 'IdentificacionTercero'])\n",
    "        ])\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('regresion', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "        ])\n",
    "\n",
    "        pipeline.fit(X, y)\n",
    "        y_pred = pipeline.predict(X)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "\n",
    "        # Generar 12 meses futuros\n",
    "        ultima_fecha = df_hist_grouped['FechaElaboracion'].max()\n",
    "        fechas_futuras = pd.date_range(start=ultima_fecha + offsets.MonthBegin(1), periods=12, freq='MS')\n",
    "\n",
    "        categoria = df_hist_grouped['Categoria'].mode()[0]\n",
    "        tipomatricula = df_hist_grouped['TipoMatricula'].mode()[0]\n",
    "        tercero = df_hist_grouped['IdentificacionTercero'].mode()[0]\n",
    "\n",
    "        df_futuro = pd.DataFrame({\n",
    "            'A帽o': fechas_futuras.year,\n",
    "            'Mes': fechas_futuras.month,\n",
    "            'TipoMantenimiento': tipo,\n",
    "            'Categoria': categoria,\n",
    "            'TipoMatricula': tipomatricula,\n",
    "            'NombreVehiculo': vehiculo,\n",
    "            'IdentificacionTercero': tercero,\n",
    "            'FechaElaboracion': fechas_futuras\n",
    "        })\n",
    "\n",
    "        y_futuro = pipeline.predict(df_futuro.drop(columns='FechaElaboracion'))\n",
    "        df_futuro['Debito'] = y_futuro\n",
    "        df_futuro['Prediccion'] = y_futuro\n",
    "        df_futuro['R2'] = r2\n",
    "        df_futuro['Origen'] = 'Predicci贸n'\n",
    "\n",
    "        df_hist_grouped['Prediccion'] = y_pred\n",
    "        df_hist_grouped['R2'] = r2\n",
    "        df_hist_grouped['Origen'] = 'Hist贸rico'\n",
    "\n",
    "        df_resultado = pd.concat([\n",
    "            df_hist_grouped[['FechaElaboracion', 'Debito', 'Prediccion', 'R2', 'Origen', 'NombreVehiculo', 'TipoMantenimiento']],\n",
    "            df_futuro[['FechaElaboracion', 'Debito', 'Prediccion', 'R2', 'Origen', 'NombreVehiculo', 'TipoMantenimiento']]\n",
    "        ]).sort_values(by='FechaElaboracion')\n",
    "\n",
    "        resultados.append(df_resultado)\n",
    "\n",
    "        #  Generar gr谩fico\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        df_h = df_resultado[df_resultado['Origen'] == 'Hist贸rico']\n",
    "        df_p = df_resultado[df_resultado['Origen'] == 'Predicci贸n']\n",
    "\n",
    "        plt.plot(df_h['FechaElaboracion'], df_h['Debito'], marker='o', linestyle='-', label='Hist贸rico')\n",
    "        plt.plot(df_p['FechaElaboracion'], df_p['Prediccion'], marker='x', linestyle='--', color='orange', label='Predicci贸n')\n",
    "\n",
    "        plt.title(f\"{vehiculo} - Tipo: {tipo}\")\n",
    "        plt.xlabel(\"Fecha\")\n",
    "        plt.ylabel(\"Costo (D茅bito)\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "        plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "        plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.text(0.98, 0.02, f\"R虏 = {r2:.4f}\", transform=plt.gca().transAxes,\n",
    "                 fontsize=10, ha='right', va='bottom',\n",
    "                 bbox=dict(facecolor='white', alpha=0.6, edgecolor='gray'))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        file_name = f\"graficas_rf_vehiculo/{vehiculo.replace(' ', '_')}_{tipo.replace(' ', '_')}.png\"\n",
    "        plt.savefig(file_name)\n",
    "        plt.close()\n",
    "\n",
    "#  Exportar Excel\n",
    "df_final = pd.concat(resultados, ignore_index=True)\n",
    "df_final.to_excel(\"Prediccion_Costos_RF_Por_Vehiculo_Tipo.xlsx\", index=False)\n",
    "\n",
    "#  Insertar en la tabla MySQL: Predicciones_Vehiculo_Tipo\n",
    "df_insert = df_final[['NombreVehiculo', 'TipoMantenimiento', 'FechaElaboracion', 'Debito', 'Origen']].copy()\n",
    "df_insert.columns = ['NombreVehiculo', 'TipoMantenimiento', 'Fecha', 'Costo', 'Origen']\n",
    "df_insert = df_insert.dropna(subset=['Costo'])\n",
    "df_insert['Costo'] = df_insert['Costo'].round(2)\n",
    "\n",
    "# Conexi贸n SQLAlchemy\n",
    "DB_URL = f\"mysql+mysqlconnector://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for _, row in df_insert.iterrows():\n",
    "        query_insert = text(\"\"\"\n",
    "            INSERT INTO Predicciones_Vehiculo_Tipo (NombreVehiculo, TipoMantenimiento, Fecha, Costo, Origen)\n",
    "            VALUES (:NombreVehiculo, :TipoMantenimiento, :Fecha, :Costo, :Origen)\n",
    "            ON DUPLICATE KEY UPDATE Costo = VALUES(Costo)\n",
    "        \"\"\")\n",
    "        conn.execute(query_insert, {\n",
    "            \"NombreVehiculo\": row['NombreVehiculo'],\n",
    "            \"TipoMantenimiento\": row['TipoMantenimiento'],\n",
    "            \"Fecha\": row['Fecha'],\n",
    "            \"Costo\": row['Costo'],\n",
    "            \"Origen\": row['Origen']\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702a072-cd2f-4fcc-9f58-84d0de4d9000",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generaci贸n de predicci贸n general por tipo de mantenimiento\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime\n",
    "import pandas.tseries.offsets as offsets\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "#  CONEXIN A LA BASE DE DATOS\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"roundhouse.proxy.rlwy.net\",\n",
    "    \"port\": 38517,\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"wZGotyxIDqpAtQjPxNuxxezSbbroztiw\",\n",
    "    \"database\": \"railway\"\n",
    "}\n",
    "\n",
    "#  CONSULTA\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    FechaElaboracion,\n",
    "    Debito,\n",
    "    TipoMantenimiento,\n",
    "    Categoria,\n",
    "    TipoMatricula,\n",
    "    NombreVehiculo,\n",
    "    IdentificacionTercero\n",
    "FROM Hechos_Mantenimiento\n",
    "WHERE Debito IS NOT NULL \n",
    "  AND FechaElaboracion IS NOT NULL\n",
    "  AND TipoMantenimiento IS NOT NULL\n",
    "  AND Categoria IS NOT NULL\n",
    "  AND TipoMatricula IS NOT NULL\n",
    "  AND NombreVehiculo IS NOT NULL\n",
    "  AND IdentificacionTercero IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "#  CARGAR DATOS\n",
    "conn = mysql.connector.connect(**DB_CONFIG)\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "df['FechaElaboracion'] = pd.to_datetime(df['FechaElaboracion'])\n",
    "\n",
    "#  CARPETA PARA GRFICAS\n",
    "os.makedirs(\"graficas_rf_agrupado\", exist_ok=True)\n",
    "resultados = []\n",
    "\n",
    "#  POR CADA TIPO DE MANTENIMIENTO\n",
    "for tipo in df['TipoMantenimiento'].unique():\n",
    "    df_tipo = df[df['TipoMantenimiento'] == tipo].copy()\n",
    "\n",
    "    #  AGRUPAR POR MES\n",
    "    df_tipo['A帽oMes'] = df_tipo['FechaElaboracion'].dt.to_period('M')\n",
    "    df_hist_grouped = df_tipo.groupby('A帽oMes').agg({\n",
    "        'Debito': 'sum',\n",
    "        'Categoria': lambda x: x.mode()[0],\n",
    "        'TipoMatricula': lambda x: x.mode()[0],\n",
    "        'NombreVehiculo': lambda x: x.mode()[0],\n",
    "        'IdentificacionTercero': lambda x: x.mode()[0]\n",
    "    }).reset_index()\n",
    "\n",
    "    df_hist_grouped['FechaElaboracion'] = df_hist_grouped['A帽oMes'].dt.to_timestamp()\n",
    "    df_hist_grouped['A帽o'] = df_hist_grouped['FechaElaboracion'].dt.year\n",
    "    df_hist_grouped['Mes'] = df_hist_grouped['FechaElaboracion'].dt.month\n",
    "    df_hist_grouped['TipoMantenimiento'] = tipo\n",
    "\n",
    "    #  ENTRENAR MODELO\n",
    "    X = df_hist_grouped[['A帽o', 'Mes', 'TipoMantenimiento', 'Categoria', 'TipoMatricula', 'NombreVehiculo', 'IdentificacionTercero']]\n",
    "    y = df_hist_grouped['Debito']\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), ['A帽o', 'Mes']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['TipoMantenimiento', 'Categoria', 'TipoMatricula', 'NombreVehiculo', 'IdentificacionTercero'])\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('regresion', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X, y)\n",
    "    y_pred = pipeline.predict(X)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "\n",
    "    #  GENERAR 12 MESES FUTUROS\n",
    "    ultima_fecha = df_hist_grouped['FechaElaboracion'].max()\n",
    "    fechas_futuras = pd.date_range(start=ultima_fecha + offsets.MonthBegin(1), periods=12, freq='MS')\n",
    "\n",
    "    categoria = df_hist_grouped['Categoria'].mode()[0]\n",
    "    tipomatricula = df_hist_grouped['TipoMatricula'].mode()[0]\n",
    "    vehiculo = df_hist_grouped['NombreVehiculo'].mode()[0]\n",
    "    tercero = df_hist_grouped['IdentificacionTercero'].mode()[0]\n",
    "\n",
    "    df_futuro = pd.DataFrame({\n",
    "        'A帽o': fechas_futuras.year,\n",
    "        'Mes': fechas_futuras.month,\n",
    "        'TipoMantenimiento': tipo,\n",
    "        'Categoria': categoria,\n",
    "        'TipoMatricula': tipomatricula,\n",
    "        'NombreVehiculo': vehiculo,\n",
    "        'IdentificacionTercero': tercero,\n",
    "        'FechaElaboracion': fechas_futuras\n",
    "    })\n",
    "\n",
    "    y_futuro = pipeline.predict(df_futuro.drop(columns='FechaElaboracion'))\n",
    "    df_futuro['Debito'] = y_futuro\n",
    "    df_futuro['Prediccion'] = y_futuro\n",
    "    df_futuro['R2'] = r2\n",
    "    df_futuro['Origen'] = 'Predicci贸n'\n",
    "\n",
    "    df_hist_grouped['Prediccion'] = y_pred\n",
    "    df_hist_grouped['R2'] = r2\n",
    "    df_hist_grouped['Origen'] = 'Hist贸rico'\n",
    "\n",
    "    df_resultado = pd.concat([\n",
    "        df_hist_grouped[['FechaElaboracion', 'Debito', 'Prediccion', 'R2', 'Origen', 'TipoMantenimiento']],\n",
    "        df_futuro[['FechaElaboracion', 'Debito', 'Prediccion', 'R2', 'Origen', 'TipoMantenimiento']]\n",
    "    ]).sort_values(by='FechaElaboracion')\n",
    "\n",
    "    resultados.append(df_resultado)\n",
    "\n",
    "    #  GRAFICAR\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    df_h = df_resultado[df_resultado['Origen'] == 'Hist贸rico']\n",
    "    df_p = df_resultado[df_resultado['Origen'] == 'Predicci贸n']\n",
    "\n",
    "    plt.plot(df_h['FechaElaboracion'], df_h['Debito'], marker='o', linestyle='-', label='Hist贸rico')\n",
    "    plt.plot(df_p['FechaElaboracion'], df_p['Prediccion'], marker='x', linestyle='--', color='orange', label='Predicci贸n')\n",
    "\n",
    "    plt.title(f\"Costo Mantenimiento - Tipo: {tipo}\")\n",
    "    plt.xlabel(\"Fecha\")\n",
    "    plt.ylabel(\"Costo (D茅bito)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.text(\n",
    "        0.98, 0.02, f\"R虏 = {r2:.4f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=10, ha='right', va='bottom',\n",
    "        bbox=dict(facecolor='white', alpha=0.6, edgecolor='gray')\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    archivo = f\"graficas_rf_agrupado/Modelo_RF_{tipo.replace(' ', '_')}.png\"\n",
    "    plt.savefig(archivo)\n",
    "    plt.close()\n",
    "\n",
    "#  EXPORTAR A EXCEL\n",
    "df_final = pd.concat(resultados, ignore_index=True)\n",
    "df_final.to_excel(\"Prediccion_Costos_RF_Mensual_Agrupado.xlsx\", index=False)\n",
    "\n",
    "#  INSERTAR EN MYSQL: Predicciones_Tipo_Mantenimiento\n",
    "df_insert = df_final[['TipoMantenimiento', 'FechaElaboracion', 'Debito', 'Origen']].copy()\n",
    "df_insert.columns = ['TipoMantenimiento', 'Fecha', 'Costo', 'Origen']\n",
    "df_insert = df_insert.dropna(subset=['Costo'])\n",
    "df_insert['Costo'] = df_insert['Costo'].round(2)\n",
    "\n",
    "#  Conexi贸n con SQLAlchemy\n",
    "DB_URL = f\"mysql+mysqlconnector://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for _, row in df_insert.iterrows():\n",
    "        query_insert = text(\"\"\"\n",
    "            INSERT INTO Predicciones_Tipo_Mantenimiento (TipoMantenimiento, Fecha, Costo, Origen)\n",
    "            VALUES (:TipoMantenimiento, :Fecha, :Costo, :Origen)\n",
    "            ON DUPLICATE KEY UPDATE Costo = VALUES(Costo)\n",
    "        \"\"\")\n",
    "        conn.execute(query_insert, {\n",
    "            \"TipoMantenimiento\": row['TipoMantenimiento'],\n",
    "            \"Fecha\": row['Fecha'],\n",
    "            \"Costo\": row['Costo'],\n",
    "            \"Origen\": row['Origen']\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881635b5-2dc2-495f-a901-211be5330f10",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.048082,
   "end_time": "2025-07-15T16:33:58.474642",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/generacion de predicciones v2.ipynb",
   "output_path": "notebooks/output/generacion de predicciones v2_20250715_123354.ipynb",
   "parameters": {},
   "start_time": "2025-07-15T16:33:54.426560",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}